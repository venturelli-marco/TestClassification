{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from scipy import ndimage, misc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob\n",
    "\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyVGG16Model():\n",
    "    # VGG16 default input\n",
    "    input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "    # load pretrained VGG16 network (only conv layer)\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "    print(vgg16.summary())\n",
    "\n",
    "    # add dense layer to perform classification for 5 classes\n",
    "    class_model = Sequential()\n",
    "    class_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "    class_model.add(Dense(512, activation='relu'))\n",
    "    class_model.add(Dropout(0.5))\n",
    "    class_model.add(Dense(256, activation='relu'))\n",
    "    class_model.add(Dropout(0.5))\n",
    "    class_model.add(Dense(5, activation='softmax'))\n",
    "    print(class_model.summary())\n",
    "\n",
    "    # use transfer learning -> use trained feature for first layers and fine tuned the last one (conv+dense)\n",
    "    model = Model(input=vgg16.input, output=class_model(vgg16.output))\n",
    "    for layer in model.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # model summary\n",
    "    print(model.summary())\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSampleFlipped(dir_path):\n",
    "    \"\"\"\n",
    "    Increase the number of sample applying image transformation (rotation+flip)\n",
    "    :param dir_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for f in glob.glob(dir_path + \"/*.png\", recursive=True):\n",
    "        img = misc.imread(f)\n",
    "\n",
    "        img = np.fliplr(img)\n",
    "\n",
    "        sign = -1\n",
    "        if random.random() > 0.5:\n",
    "            sign = 1\n",
    "\n",
    "        img = ndimage.rotate(img, random.randint(2,20)*sign, mode='constant', cval=255)\n",
    "\n",
    "        f_rot = os.path.splitext(f)[0] + \"_rot\" + \".png\"\n",
    "        misc.imsave(f_rot, img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceDataset(path, path_val, min_file_per_class=500):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and validation with the same number of samples foreach training class\n",
    "    :param path:\n",
    "    :param path_val:\n",
    "    :param min_file_per_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, dir in enumerate(os.listdir(path)):\n",
    "        # validation directory tree\n",
    "        if not os.path.exists(path_val + \"/\" + dir):\n",
    "            os.makedirs(path_val + \"/\" + dir)\n",
    "\n",
    "        # images files\n",
    "        files = glob.glob(path + \"/\" + dir + \"/*.png\", recursive=False)\n",
    "        num_imgs = len(files)\n",
    "\n",
    "        # dataset already splitted\n",
    "        if(num_imgs == min_file_per_class):\n",
    "            break\n",
    "\n",
    "        # add new samples for classes with few elements\n",
    "        if num_imgs < min_file_per_class:\n",
    "            addSampleFlipped(path + \"/\" + dir)\n",
    "            files = glob.glob(path + \"/\" + dir + \"/*.png\", recursive=False)\n",
    "            num_imgs = len(files)\n",
    "\n",
    "        # randomly select validation file\n",
    "        idx = random.sample(range(num_imgs), num_imgs - min_file_per_class)\n",
    "        for i in idx:\n",
    "            os.rename(files[i], path_val + files[i][files[i].find(path) + len(path):])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSamples(data, channels=3, img_rows=224, img_cols=224):\n",
    "    \"\"\"\n",
    "    load images and label from file\n",
    "    :param data: list of tuple (y, file_path)\n",
    "    :param channels:\n",
    "    :param img_rows:\n",
    "    :param img_cols:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # initialize output tensor\n",
    "    X = np.zeros((len(data), img_rows, img_cols, channels))\n",
    "    Y = np.zeros((len(data), 1))\n",
    "\n",
    "    for i,(y, f) in enumerate(data):\n",
    "        img = misc.imread(f)\n",
    "        img = img.astype('float32')\n",
    "        img = misc.imresize(img, (img_rows, img_cols, channels))\n",
    "        img = img / 255\n",
    "\n",
    "        Y[i] = y\n",
    "        X[i] = img\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamplesData(path):\n",
    "    \"\"\"\n",
    "    Load a list of tuple (label, file_path). Label is the numeric index of the directory\n",
    "    :param path: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, dir in enumerate(os.listdir(path)):\n",
    "        for f in glob.glob(path + \"/\" + dir + \"/*.png\", recursive=True):\n",
    "            data.append([i, f])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_training = 'dati_maniche'\n",
    "path_validation = 'dati_maniche_val'\n",
    "\n",
    "# Create a balanced dataset: classes will have the same number of samples in training dataset (500)\n",
    "# Training and validation are splitted randomly in 2 folder\n",
    "balanceDataset(path_training, path_validation)\n",
    "\n",
    "# Get model\n",
    "model = MyVGG16Model()\n",
    "\n",
    "#optimizer = SGD(lr=1e-4, decay=0.005, momentum=0.9, nesterov=True)\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# set training callbacks: stop if validation loss increase (probably is overfitting) and save weights with the lower loss\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
    "ckpt = ModelCheckpoint('weights/weights.{epoch:03d}-{val_loss:.5f}.hdf5', save_best_only=True, monitor='val_loss', mode='min')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use keras API to apply data augmentation (add random samples to our dataset to increase generalization)\n",
    "gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=False,\n",
    "                         width_shift_range=10,\n",
    "                         height_shift_range=0.2,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range=0.2,\n",
    "                         rescale=1. / 255,\n",
    "                         rotation_range=10)\n",
    "# On validation dataset apply only rescale\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Use keras API for loading the sample for training -> samples are automatically labeled from directory\n",
    "# this API ensure images and label will be loaded in loop\n",
    "train_generator = gen.flow_from_directory(\n",
    "    path_training,\n",
    "    target_size=(224, 224),     # Resize images\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',   # convert labels to categorical\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# Use keras API for loading the sample for training\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    path_validation,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with generator\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    callbacks=[earlyStopping, ckpt],\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify on validation data -> it could be a better idea to use other examples but the number of samples was not so high\n",
    "data = getSamplesData(path_validation)\n",
    "X, Y = loadSamples(data)\n",
    "Y = Y.reshape((Y.shape[0]))\n",
    "print(Y)\n",
    "\n",
    "print(\"Loading Weights...\")\n",
    "model.load_weights('weights/weights.hdf5')\n",
    "\n",
    "pred = model.predict(X)\n",
    "predicted_classes = np.argmax(pred, axis=1)  # take the argmax -> output with the higher score define the class\n",
    "\n",
    "print(predicted_classes)\n",
    "\n",
    "# numbers of miss prediction\n",
    "errors = np.where(predicted_classes != Y)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors), validation_generator.samples))\n",
    "\n",
    "# confusion matrix\n",
    "conf_matrix = confusion_matrix(Y, predicted_classes)\n",
    "print(conf_matrix)\n",
    "\n",
    "# in my test, there are a lot of bad prediction between maniche_a_34 and maniche_lunghe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
