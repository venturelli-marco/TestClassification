{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from scipy import ndimage, misc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob\n",
    "\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyVGG16Model():\n",
    "    # VGG16 default input\n",
    "    input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "    # load pretrained VGG16 network (only conv layer)\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "    print(vgg16.summary())\n",
    "\n",
    "    # add dense layer to perform classification for 5 classes\n",
    "    class_model = Sequential()\n",
    "    class_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "    class_model.add(Dense(512, activation='relu'))\n",
    "    class_model.add(Dropout(0.5))\n",
    "    class_model.add(Dense(256, activation='relu'))\n",
    "    class_model.add(Dropout(0.5))\n",
    "    class_model.add(Dense(5, activation='softmax'))\n",
    "    print(class_model.summary())\n",
    "\n",
    "    # use transfer learning -> use trained feature for first layers and fine tuned the last one (conv+dense)\n",
    "    model = Model(input=vgg16.input, output=class_model(vgg16.output))\n",
    "    for layer in model.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # model summary\n",
    "    print(model.summary())\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSampleFlipped(dir_path):\n",
    "    \"\"\"\n",
    "    Increase the number of sample applying image transformation (rotation+flip)\n",
    "    :param dir_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for f in glob.glob(dir_path + \"/*.png\", recursive=True):\n",
    "        img = misc.imread(f)\n",
    "\n",
    "        img = np.fliplr(img)\n",
    "\n",
    "        sign = -1\n",
    "        if random.random() > 0.5:\n",
    "            sign = 1\n",
    "\n",
    "        img = ndimage.rotate(img, random.randint(2,20)*sign, mode='constant', cval=255)\n",
    "\n",
    "        f_rot = os.path.splitext(f)[0] + \"_rot\" + \".png\"\n",
    "        misc.imsave(f_rot, img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceDataset(path, path_val, min_file_per_class=500):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and validation with the same number of samples foreach training class\n",
    "    :param path:\n",
    "    :param path_val:\n",
    "    :param min_file_per_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, dir in enumerate(os.listdir(path)):\n",
    "        # validation directory tree\n",
    "        if not os.path.exists(path_val + \"/\" + dir):\n",
    "            os.makedirs(path_val + \"/\" + dir)\n",
    "\n",
    "        # images files\n",
    "        files = glob.glob(path + \"/\" + dir + \"/*.png\", recursive=False)\n",
    "        num_imgs = len(files)\n",
    "\n",
    "        # dataset already splitted\n",
    "        if(num_imgs == min_file_per_class):\n",
    "            break\n",
    "\n",
    "        # add new samples for classes with few elements\n",
    "        if num_imgs < min_file_per_class:\n",
    "            addSampleFlipped(path + \"/\" + dir)\n",
    "            files = glob.glob(path + \"/\" + dir + \"/*.png\", recursive=False)\n",
    "            num_imgs = len(files)\n",
    "\n",
    "        # randomly select validation file\n",
    "        idx = random.sample(range(num_imgs), num_imgs - min_file_per_class)\n",
    "        for i in idx:\n",
    "            os.rename(files[i], path_val + files[i][files[i].find(path) + len(path):])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSamples(data, channels=3, img_rows=224, img_cols=224):\n",
    "    \"\"\"\n",
    "    load images and label from file\n",
    "    :param data: list of tuple (y, file_path)\n",
    "    :param channels:\n",
    "    :param img_rows:\n",
    "    :param img_cols:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # initialize output tensor\n",
    "    X = np.zeros((len(data), img_rows, img_cols, channels))\n",
    "    Y = np.zeros((len(data), 1))\n",
    "\n",
    "    for i,(y, f) in enumerate(data):\n",
    "        img = misc.imread(f)\n",
    "        img = img.astype('float32')\n",
    "        img = misc.imresize(img, (img_rows, img_cols, channels))\n",
    "        img = img / 255\n",
    "\n",
    "        Y[i] = y\n",
    "        X[i] = img\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamplesData(path):\n",
    "    \"\"\"\n",
    "    Load a list of tuple (label, file_path). Label is the numeric index of the directory\n",
    "    :param path: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, dir in enumerate(os.listdir(path)):\n",
    "        for f in glob.glob(path + \"/\" + dir + \"/*.png\", recursive=True):\n",
    "            data.append([i, f])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: 'dati_maniche'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8b7aa7e16b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a balanced dataset: classes will have the same number of samples in training dataset (500)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Training and validation are splitted randomly in 2 folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbalanceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Get model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1bd2497146fb>\u001b[0m in \u001b[0;36mbalanceDataset\u001b[1;34m(path, path_val, min_file_per_class)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m      9\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# validation directory tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_val\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: 'dati_maniche'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "path_training = 'dati_maniche'\n",
    "path_validation = 'dati_maniche_val'\n",
    "\n",
    "# Create a balanced dataset: classes will have the same number of samples in training dataset (500)\n",
    "# Training and validation are splitted randomly in 2 folder\n",
    "balanceDataset(path_training, path_validation)\n",
    "\n",
    "# Get model\n",
    "model = MyVGG16Model()\n",
    "\n",
    "#optimizer = SGD(lr=1e-4, decay=0.005, momentum=0.9, nesterov=True)\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# set training callbacks: stop if validation loss increase (probably is overfitting) and save weights with the lower loss\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
    "ckpt = ModelCheckpoint('weights/weights.{epoch:03d}-{val_loss:.5f}.hdf5', save_best_only=True, monitor='val_loss', mode='min')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: 'dati_maniche'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d5f9e1802d33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical'\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;31m# convert labels to categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     shuffle=True)\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Use keras API for loading the sample for training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             interpolation=interpolation)\n\u001b[0m\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: 'dati_maniche'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Use keras API to apply data augmentation (add random samples to our dataset to increase generalization)\n",
    "gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=False,\n",
    "                         width_shift_range=10,\n",
    "                         height_shift_range=0.2,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range=0.2,\n",
    "                         rescale=1. / 255,\n",
    "                         rotation_range=10)\n",
    "# On validation dataset apply only rescale\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Use keras API for loading the sample for training -> samples are automatically labeled from directory\n",
    "# this API ensure images and label will be loaded in loop\n",
    "train_generator = gen.flow_from_directory(\n",
    "    path_training,\n",
    "    target_size=(224, 224),     # Resize images\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',   # convert labels to categorical\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# Use keras API for loading the sample for training\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    path_validation,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with generator\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    callbacks=[earlyStopping, ckpt],\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples/validation_generator.batch_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: 'dati_maniche_val'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1c979cd85024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Verify on validation data -> it could be a better idea to use other examples but the number of samples was not so high\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetSamplesData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadSamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-939715cc03c3>\u001b[0m in \u001b[0;36mgetSamplesData\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetSamplesData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/*.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: 'dati_maniche_val'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Verify on validation data -> it could be a better idea to use other examples but the number of samples was not so high\n",
    "data = getSamplesData(path_validation)\n",
    "X, Y = loadSamples(data)\n",
    "Y = Y.reshape((Y.shape[0]))\n",
    "print(Y)\n",
    "\n",
    "print(\"Loading Weights...\")\n",
    "model.load_weights('weights/weights.hdf5')\n",
    "\n",
    "pred = model.predict(X)\n",
    "predicted_classes = np.argmax(pred, axis=1)  # take the argmax -> output with the higher score define the class\n",
    "\n",
    "print(predicted_classes)\n",
    "\n",
    "# numbers of miss prediction\n",
    "errors = np.where(predicted_classes != Y)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors), validation_generator.samples))\n",
    "\n",
    "# confusion matrix\n",
    "conf_matrix = confusion_matrix(Y, predicted_classes)\n",
    "print(conf_matrix)\n",
    "\n",
    "# in my test, there are a lot of bad prediction between maniche_a_34 and maniche_lunghe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
